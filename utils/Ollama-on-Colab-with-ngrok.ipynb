{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_iKD3JuEQZx"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7836,
     "status": "ok",
     "timestamp": 1720690284479,
     "user": {
      "displayName": "Beat Buster",
      "userId": "15185542700030268389"
     },
     "user_tz": -120
    },
    "id": "cOM1AFukDvzJ",
    "outputId": "40be63fa-bedc-4eca-f76b-f1203add6b44"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "pciutils is already the newest version (1:3.7.0-6).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0>>> Downloading ollama...\n",
      "100 10975    0 10975    0     0  40000      0 --:--:-- --:--:-- --:--:-- 40054\n",
      "############################################################################################# 100.0%\n",
      ">>> Installing ollama to /usr/local/bin...\n",
      ">>> Adding ollama user to video group...\n",
      ">>> Adding current user to ollama group...\n",
      ">>> Creating ollama systemd service...\n",
      ">>> NVIDIA GPU installed.\n",
      ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
      ">>> Install complete. Run \"ollama\" from the command line.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install -y pciutils && \\\n",
    "    curl https://ollama.ai/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install pyngrok"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ZM9DTana7HeW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1720690292786,
     "user_tz": -120,
     "elapsed": 8309,
     "user": {
      "displayName": "Beat Buster",
      "userId": "15185542700030268389"
     }
    },
    "outputId": "518aaf04-3b80-473a-b81a-c2120ac7deee"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import threading\n",
    "import subprocess\n",
    "\n",
    "import requests\n",
    "from pyngrok import ngrok, conf\n",
    "from google.colab import userdata"
   ],
   "metadata": {
    "id": "iMY0uuXX9KDY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1720690292787,
     "user_tz": -120,
     "elapsed": 5,
     "user": {
      "displayName": "Beat Buster",
      "userId": "15185542700030268389"
     }
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def ollama():\n",
    "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
    "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
    "    os.environ['OLLAMA_KEEP_ALIVE'] = '-1'\n",
    "    subprocess.Popen([\"ollama\", \"serve\"])"
   ],
   "metadata": {
    "id": "5aP6HNcvA5Mb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1720690292787,
     "user_tz": -120,
     "elapsed": 4,
     "user": {
      "displayName": "Beat Buster",
      "userId": "15185542700030268389"
     }
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ollama_thread = threading.Thread(target=ollama)\n",
    "ollama_thread.start()"
   ],
   "metadata": {
    "id": "gvK27aucBFbf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1720690292787,
     "user_tz": -120,
     "elapsed": 4,
     "user": {
      "displayName": "Beat Buster",
      "userId": "15185542700030268389"
     }
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!ollama pull gemma:7b\n",
    "!ollama pull mistral\n",
    "!ollama pull internlm2"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "SAX2YoLIBxlI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1720690293282,
     "user_tz": -120,
     "elapsed": 499,
     "user": {
      "displayName": "Beat Buster",
      "userId": "15185542700030268389"
     }
    },
    "outputId": "e11aeb4d-471d-4e3c-a7ff-53eb827917b6"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[?25lpulling manifest ⠋ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest ⠙ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest ⠹ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest ⠸ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest \n",
      "pulling fc9cdb4d5d78... 100% ▕▏ 4.5 GB                         \n",
      "pulling 75357d685f23... 100% ▕▏   28 B                         \n",
      "pulling 62fbfd9ed093... 100% ▕▏  182 B                         \n",
      "pulling c71d239df917... 100% ▕▏  11 KB                         \n",
      "pulling f02dd72bb242... 100% ▕▏   59 B                         \n",
      "pulling b10233a80e1a... 100% ▕▏  567 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "removing any unused layers \n",
      "success \u001B[?25h\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "conf.get_default().auth_token = userdata.get('NGROK_AUTH')\n",
    "ollama_tunnel = ngrok.connect(\"11434\", \"http\")\n",
    "public_url = ollama_tunnel.public_url\n",
    "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://0.0.0.0:11434\\\"\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "61_yIXN68pZo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1720690294918,
     "user_tz": -120,
     "elapsed": 1639,
     "user": {
      "displayName": "Beat Buster",
      "userId": "15185542700030268389"
     }
    },
    "outputId": "feb8c45f-0c2b-4ded-85ae-ec5b48a963d4"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * ngrok tunnel \"https://1cb1-34-105-101-66.ngrok-free.app\" -> \"http://0.0.0.0:11434\"\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "authorship_tag": "ABX9TyO05iQppEMAXUsqVUL9xBQB"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
